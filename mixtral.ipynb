{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from clarifai.client.model import Model\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "import os\n",
    "clarifai_pat = os.getenv('CLARIFAI_PAT')\n",
    "OpenAI_API_KEY = os.getenv('OpenAI_API_KEY')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The future of AI is a topic of much discussion and debate among experts. Here are a few possibilities:\n",
      "\n",
      "1. Advancements in machine learning and deep learning will continue to drive improvements in AI's ability to understand and interpret data, leading to more sophisticated and capable AI systems.\n",
      "2. AI will become more integrated into our daily lives, from home appliances and personal devices to transportation and the workplace.\n",
      "3. The development of \"explainable AI\" will become a priority, as there is a growing recognition of the need for AI systems to be transparent and understandable to human users.\n",
      "4. AI will play an increasingly important role in scientific research and discovery, as it can process and analyze vast amounts of data more quickly and accurately than humans.\n",
      "5. Ethical and societal implications of AI will continue to be a major focus of debate and discussion, as AI becomes more prevalent and powerful.\n",
      "6. There will be a growing need for regulations\n"
     ]
    }
   ],
   "source": [
    "prompt = \"<s> [INST] Whatâ€™s the futuree of AI? [/INST]\"\n",
    "\n",
    "inference_params = dict(temperature=0.7, max_tokens=200, top_k = 50, top_p= 0.95)\n",
    "\n",
    "# Model Predict\n",
    "model_prediction = Model(\"https://clarifai.com/mistralai/completion/models/mixtral-8x7B-Instruct-v0_1\").predict_by_bytes(prompt.encode(), input_type=\"text\", inference_params=inference_params)\n",
    "\n",
    "print(model_prediction.outputs[0].data.text.raw)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
